{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import write_dot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display_png\n",
    "import json\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from karateclub.node_embedding.neighbourhood.deepwalk import DeepWalk\n",
    "from nodevectors import Node2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training preprocessing done\n",
      "test preprocessing done\n"
     ]
    }
   ],
   "source": [
    "def flatten(list_of_list):\n",
    "    return [item for sublist in list_of_list for item in sublist]\n",
    "\n",
    "def load_data(transcription_id, labels, data_type='training'):\n",
    "    with open(f'{data_type}/{transcription_id}.json', 'r') as json_file:\n",
    "        discourse_data = json.load(json_file)\n",
    "\n",
    "    with open(f'{data_type}/{transcription_id}.txt', 'r') as txt_file:\n",
    "        discourse_types = [line.strip().split() for line in txt_file]\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for entry in discourse_data:\n",
    "        G.add_node(entry['index'], speaker=entry['speaker'], text=entry['text'])\n",
    "\n",
    "    for discourse_relation in discourse_types:\n",
    "        node_from = int(discourse_relation[0])\n",
    "        node_to = int(discourse_relation[-1])\n",
    "        relation_type = discourse_relation[1]\n",
    "\n",
    "        if G.has_node(node_from) and G.has_node(node_to):\n",
    "            G.add_edge(node_from, node_to, type=relation_type)\n",
    "\n",
    "    label = labels[transcription_id]\n",
    "    \n",
    "    return G, label\n",
    "\n",
    "def precompute_embeddings(bert, data):\n",
    "    embeddings = []\n",
    "    for G, _ in data:\n",
    "        deepwalk = DeepWalk()\n",
    "        deepwalk.fit(G)\n",
    "        embedding = deepwalk.get_embedding()\n",
    "        embeddings.append(embedding)\n",
    "    return flatten(embeddings)\n",
    "\n",
    "# training and test sets of transcription ids\n",
    "training_set = ['ES2002', 'ES2006','IS1003','IS1005', 'TS3012','TS3005']\n",
    "#, 'ES2007', 'ES2008', 'ES2009', 'ES2010', 'ES2012', 'ES2013','ES2015',  'IS1004', 'IS1006', 'IS1007', 'TS3008', 'TS3009', 'TS3010', \n",
    "training_set = flatten([[m_id + s_id for s_id in 'abcd'] for m_id in training_set])\n",
    "\n",
    "training_set.remove('IS1005d')\n",
    "training_set.remove('TS3012c')\n",
    "\n",
    "test_set = ['ES2005','IS1002', 'TS3011']\n",
    "#'ES2016', 'IS1000', 'IS1001', \n",
    "            #, 'ES2004', 'ES2011']\n",
    "            #, 'ES2014', 'IS1008', 'IS1009','TS3003', 'TS3004', 'TS3006', 'TS3007']\n",
    "\n",
    "test_set = flatten([[m_id + s_id for s_id in 'abcd'] for m_id in test_set])\n",
    "test_set.remove('IS1002a')\n",
    "\n",
    "# training graph preprocessing\n",
    "bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "with open(\"training_labels.json\", \"r\") as file:\n",
    "    training_labels = json.load(file)\n",
    "\n",
    "y_training = []\n",
    "X_training_data = [load_data(transcription_id, training_labels) for transcription_id in training_set]\n",
    "y_training = flatten([label for _, label in X_training_data])\n",
    "X_training = precompute_embeddings(bert, X_training_data)\n",
    "print('training preprocessing done')\n",
    "\n",
    "# test graph preprocessing\n",
    "y_test = []\n",
    "X_test_data = [load_data(transcription_id, training_labels, data_type='training') for transcription_id in test_set]\n",
    "y_test = flatten([label for _, label in X_test_data])\n",
    "X_test = precompute_embeddings(bert, X_test_data)\n",
    "\n",
    "print('test preprocessing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18216318785578745"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_training, y_training)\n",
    "print('training done')\n",
    "\n",
    "# test\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m XGBClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_training, y_training)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtraining done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# test\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_training' is not defined"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "model = XGBClassifier(random_state=0)\n",
    "model.fit(X_training, y_training)\n",
    "print('training done')\n",
    "\n",
    "# test\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_training, y_training)\n",
    "print('training done')\n",
    "\n",
    "# test\n",
    "y_pred3 = model.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Add 'speaker' and 'text' attributes to the node data of DGL graphs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m g, (_, labels) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(train_graphs, X_training_data):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([g\u001b[39m.\u001b[39mnodes[n][\u001b[39m'\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([g\u001b[39m.\u001b[39mnodes[n][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m g, (_, labels) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_graphs, X_test_data):\n",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Add 'speaker' and 'text' attributes to the node data of DGL graphs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m g, (_, labels) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(train_graphs, X_training_data):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([g\u001b[39m.\u001b[39;49mnodes[n][\u001b[39m'\u001b[39;49m\u001b[39mspeaker\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([g\u001b[39m.\u001b[39mnodes[n][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()])\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m g, (_, labels) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_graphs, X_test_data):\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Assuming you have lists of speakers, texts, and labels\n",
    "speakers = ['speaker1', 'speaker2', 'speaker3', ...]\n",
    "texts = ['text1', 'text2', 'text3', ...]\n",
    "labels = [0, 1, 0, ...]  # Replace with your actual labels\n",
    "\n",
    "# Combine speakers, texts, and labels into a list of tuples\n",
    "data = list(zip(speakers, texts, labels))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "y_train = [label for _, _, label in train_data]\n",
    "y_test = [label for _, _, label in test_data]\n",
    "\n",
    "# Function to create DGL graphs and add node features\n",
    "def create_dgl_graphs(data):\n",
    "    graphs = [dgl.DGLGraph() for _ in data]\n",
    "\n",
    "    for g, (speaker, text, _) in zip(graphs, data):\n",
    "        # Add nodes\n",
    "        num_nodes = 2  # Number of nodes in each graph (assuming 2 nodes)\n",
    "        g.add_nodes(num_nodes)\n",
    "\n",
    "        # Add edges (assuming an edge between node 0 and node 1)\n",
    "        g.add_edge(0, 1)\n",
    "\n",
    "        # Add node features\n",
    "        speakers_encoded = torch.tensor([[speaker == s for s in set(speakers)]]).float()\n",
    "        texts_encoded = torch.tensor([[text == t for t in set(texts)]]).float()\n",
    "        \n",
    "        g.ndata['speaker'] = speakers_encoded\n",
    "        g.ndata['text'] = texts_encoded\n",
    "\n",
    "    return graphs\n",
    "\n",
    "# Create DGL graphs and add node features\n",
    "train_graphs = create_dgl_graphs(train_data)\n",
    "test_graphs = create_dgl_graphs(test_data)\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = dgl.nn.GraphConv(in_feats, hidden_size)\n",
    "        self.conv2 = dgl.nn.GraphConv(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        x = F.relu(self.conv1(g, g.ndata['speaker']))\n",
    "        x = F.relu(self.conv2(g, x))\n",
    "        x = dgl.mean_nodes(g, 'x')\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the GCN model\n",
    "in_feats = train_graphs[0].ndata['speaker'].shape[1] + train_graphs[0].ndata['text'].shape[1]  # Number of input features\n",
    "hidden_size = 64  # Number of hidden units\n",
    "num_classes = 2  # Number of output classes\n",
    "model = GCN(in_feats, hidden_size, num_classes)\n",
    "\n",
    "# Convert the training labels to PyTorch tensors\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = [model(g) for g in train_graphs]\n",
    "    loss = sum([criterion(output, y) for output, y in zip(outputs, y_train_tensor)])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = [model(g) for g in test_graphs]\n",
    "    y_pred = torch.argmax(torch.cat(test_outputs), dim=1)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3177, number of negative: 16089\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32640\n",
      "[LightGBM] [Info] Number of data points in the train set: 19266, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.164902 -> initscore=-1.622198\n",
      "[LightGBM] [Info] Start training from score -1.622198\n",
      "training done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# model training\n",
    "model = LGBMClassifier(random_state=0)\n",
    "model.fit(X_training, y_training)\n",
    "print('training done')\n",
    "\n",
    "# test\n",
    "y_pred_LGBM = model.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred_LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'is_directed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m graphs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Create DGL graphs and add node features\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m train_graphs \u001b[39m=\u001b[39m create_dgl_graphs(X_training)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m test_graphs \u001b[39m=\u001b[39m create_dgl_graphs(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Define the GCN model\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_dgl_graphs\u001b[39m(data):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     graphs \u001b[39m=\u001b[39m [dgl\u001b[39m.\u001b[39mfrom_networkx(G) \u001b[39mfor\u001b[39;00m G \u001b[39min\u001b[39;00m data]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m graphs:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# Extract 'speaker' and 'text' attributes\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         speakers \u001b[39m=\u001b[39m [g\u001b[39m.\u001b[39mnodes[n][\u001b[39m'\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()]\n",
      "\u001b[1;32mc:\\Users\\lelia\\Documents\\0_X3A\\INF554 - Apprentissage automatique et profond\\inf554-extractive-summarization-2023\\extract_sum_code.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_dgl_graphs\u001b[39m(data):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     graphs \u001b[39m=\u001b[39m [dgl\u001b[39m.\u001b[39;49mfrom_networkx(G) \u001b[39mfor\u001b[39;00m G \u001b[39min\u001b[39;00m data]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m graphs:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# Extract 'speaker' and 'text' attributes\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lelia/Documents/0_X3A/INF554%20-%20Apprentissage%20automatique%20et%20profond/inf554-extractive-summarization-2023/extract_sum_code.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         speakers \u001b[39m=\u001b[39m [g\u001b[39m.\u001b[39mnodes[n][\u001b[39m'\u001b[39m\u001b[39mspeaker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m g\u001b[39m.\u001b[39mnodes()]\n",
      "File \u001b[1;32mc:\\Users\\lelia\\anaconda3\\lib\\site-packages\\dgl\\convert.py:1344\u001b[0m, in \u001b[0;36mfrom_networkx\u001b[1;34m(nx_graph, node_attrs, edge_attrs, edge_id_attr_name, idtype, device)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1336\u001b[0m     edge_id_attr_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m     \u001b[39mand\u001b[39;00m edge_id_attr_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(nx_graph\u001b[39m.\u001b[39medges(data\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)))[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m   1338\u001b[0m ):\n\u001b[0;32m   1339\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\n\u001b[0;32m   1340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find the pre-specified edge IDs in the edge features of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe NetworkX graph with name \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(edge_id_attr_name)\n\u001b[0;32m   1342\u001b[0m     )\n\u001b[1;32m-> 1344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nx_graph\u001b[39m.\u001b[39;49mis_directed() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[0;32m   1345\u001b[0m     edge_id_attr_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m edge_attrs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m ):\n\u001b[0;32m   1347\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\n\u001b[0;32m   1348\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpect edge_id_attr_name and edge_attrs to be None when nx_graph is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1349\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mundirected, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(edge_id_attr_name, edge_attrs)\n\u001b[0;32m   1350\u001b[0m     )\n\u001b[0;32m   1352\u001b[0m \u001b[39m# Relabel nodes using consecutive integers starting from 0\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'is_directed'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming X_data is a list of NetworkX DiGraphs with 'speaker' and 'text' attributes\n",
    "\n",
    "# Function to create DGL graphs and add node features\n",
    "def create_dgl_graphs(data):\n",
    "    graphs = [dgl.from_networkx(G) for G in data]\n",
    "\n",
    "    for g in graphs:\n",
    "        # Extract 'speaker' and 'text' attributes\n",
    "        speakers = [g.nodes[n]['speaker'] for n in g.nodes()]\n",
    "        texts = [g.nodes[n]['text'] for n in g.nodes()]\n",
    "\n",
    "        # Encode 'speaker' and 'text' using OneHotEncoder\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        speakers_encoded = encoder.fit_transform([[s] for s in speakers])\n",
    "        texts_encoded = encoder.fit_transform([[t] for t in texts])\n",
    "\n",
    "        # Add one-hot encoded features to the node data of DGL graphs\n",
    "        g.ndata['speaker'] = torch.tensor(speakers_encoded).float()\n",
    "        g.ndata['text'] = torch.tensor(texts_encoded).float()\n",
    "\n",
    "    return graphs\n",
    "\n",
    "# Create DGL graphs and add node features\n",
    "train_graphs = create_dgl_graphs(X_training)\n",
    "test_graphs = create_dgl_graphs(X_test)\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = dgl.nn.GraphConv(in_feats, hidden_size)\n",
    "        self.conv2 = dgl.nn.GraphConv(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        x = F.relu(self.conv1(g, g.ndata['speaker']))\n",
    "        x = F.relu(self.conv2(g, x))\n",
    "        x = dgl.mean_nodes(g, 'x')\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Create the GCN model\n",
    "in_feats = train_graphs[0].ndata['speaker'].shape[1] + train_graphs[0].ndata['text'].shape[1]  # Number of input features\n",
    "hidden_size = 64  # Number of hidden units\n",
    "num_classes = 2  # Number of output classes\n",
    "model = GCN(in_feats, hidden_size, num_classes)\n",
    "\n",
    "# Convert the training labels to PyTorch tensors\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = [model(g) for g in train_graphs]\n",
    "    loss = sum([criterion(output, y) for output, y in zip(outputs, y_train_tensor)])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = [model(g) for g in test_graphs]\n",
    "    y_pred = torch.argmax(torch.cat(test_outputs), dim=1)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
